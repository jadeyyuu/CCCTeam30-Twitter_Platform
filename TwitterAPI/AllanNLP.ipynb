{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3fe186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ijson\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f00739da",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = []\n",
    "text = []\n",
    "city = []\n",
    "location =[]\n",
    "# with open(f’{tmp}_data.json’, ‘r’, encoding=’utf-8’) as f:\n",
    "with open('data.json', 'r') as f:\n",
    "    objects = ijson.items(f, 'results.item')\n",
    "    for row in objects:\n",
    "        if row['text'].startswith(\"RT\") == False:\n",
    "            city.append(row['place']['name'])\n",
    "            location.append(row['coordinates'])\n",
    "            time.append(row['created_at'])\n",
    "            text.append(row['text'])\n",
    "\n",
    "data = pd.DataFrame({\"text\":text,\"time\":time,\"city\":city,\"location\":location},columns=[\"text\",\"time\",\"city\",\"location\"])\n",
    "data['time'] = pd.to_datetime(data['time']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59493701",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('NLP').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56741de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-27 17:28:01,816] [WARNING] [W108] The rule-based lemmatizer did not find POS annotation for the token 'sad'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[2021-04-27 17:28:01,817] [WARNING] [W108] The rule-based lemmatizer did not find POS annotation for the token '!'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[2021-04-27 17:28:01,832] [WARNING] [W108] The rule-based lemmatizer did not find POS annotation for the token 'ok'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[2021-04-27 17:28:01,859] [WARNING] [W108] The rule-based lemmatizer did not find POS annotation for the token 'happy'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logits': [-1.4538416862487793, 1.420343041419983], 'probs': [0.05344456434249878, 0.9465554356575012], 'token_ids': [419, 589], 'label': '0', 'tokens': ['sad', '!']}\n",
      "{'logits': [3.149426221847534, -3.0729405879974365], 'probs': [0.9980193376541138, 0.0019806120544672012], 'token_ids': [1], 'label': '1', 'tokens': ['@@UNKNOWN@@']}\n",
      "{'logits': [4.94352912902832, -4.841168403625488], 'probs': [0.999943733215332, 5.630350278806873e-05], 'token_ids': [1036], 'label': '1', 'tokens': ['happy']}\n"
     ]
    }
   ],
   "source": [
    "print(predictor.predict(\"sad!\"))\n",
    "print(predictor.predict(\"ok\"))\n",
    "print(predictor.predict(\"happy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b0f10fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------+--------+---------------+\n",
      "|                text|      time|     city|location|sentiment_score|\n",
      "+--------------------+----------+---------+--------+---------------+\n",
      "|Brilliant thread....|2020-08-31|Melbourne|    null|              1|\n",
      "|@TimWilsonMP Have...|2020-08-31|Melbourne|    null|              1|\n",
      "|@Rdene915 @Christ...|2020-08-31|Melbourne|    null|              1|\n",
      "|A photo of you in...|2020-08-31|Melbourne|    null|              1|\n",
      "|@IndyCat14 @JoyOf...|2020-08-31|Melbourne|    null|              1|\n",
      "|@BuckleyIOP It re...|2020-08-31|Melbourne|    null|              1|\n",
      "|@kruevans But you...|2020-08-31|Melbourne|    null|              1|\n",
      "|@johniadarola I d...|2020-08-31|Melbourne|    null|              1|\n",
      "|My sister turns 7...|2020-08-31|Melbourne|    null|              1|\n",
      "|@kruevans It’s sh...|2020-08-31|Melbourne|    null|              1|\n",
      "|@runwader Cannot ...|2020-08-31|Melbourne|    null|              1|\n",
      "|@abcmelbourne mor...|2020-08-31|Melbourne|    null|              0|\n",
      "|#VICTORIA #Parlia...|2020-08-31|Melbourne|    null|              1|\n",
      "|@profsarahj Sadly...|2020-08-31|Melbourne|    null|              0|\n",
      "|@ChristineBemis2 ...|2020-08-31|Melbourne|    null|              0|\n",
      "|@MonmouthTrack Ag...|2020-08-31|Melbourne|    null|              1|\n",
      "|@CardsSIUCIllini ...|2020-08-31|Melbourne|    null|              1|\n",
      "|Beautiful Scotlan...|2020-08-31|Melbourne|    null|              1|\n",
      "|@johnweber94 @sha...|2020-08-31|Melbourne|    null|              0|\n",
      "|That's what... Ma...|2020-08-31|  Geelong|    null|              1|\n",
      "+--------------------+----------+---------+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data)\n",
    "# spacy.load('en_core_web_sm')\n",
    "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/basic_stanford_sentiment_treebank-2020.06.09.tar.gz\")\n",
    "def AllanNLP(text):\n",
    "    return predictor.predict(text)['label']\n",
    "sentiment_analysis_udf = udf(AllanNLP)\n",
    "score = sentiment_analysis_udf( df['text'] )\n",
    "\n",
    "df  = df.withColumn(\"sentiment_score\", score)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d94083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition(r):\n",
    "    if (r >=0.1):\n",
    "        label = \"positive\"\n",
    "    elif(r <= -0.1):\n",
    "        label = \"negative\"\n",
    "    else:\n",
    "        label = \"neutral\"\n",
    "    return label\n",
    "\n",
    "sentiment_udf = udf(lambda x: condition(x), StringType())\n",
    "df  = df.withColumn(\"sentiment\", sentiment_udf( df['sentiment_score'] ))\n",
    "SA_results = df.select('text','time','sentiment_score','sentiment')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
