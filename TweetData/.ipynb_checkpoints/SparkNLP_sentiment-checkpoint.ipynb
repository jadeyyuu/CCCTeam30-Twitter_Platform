{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ijson\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = []\n",
    "text = []\n",
    "city = []\n",
    "location =[]\n",
    "# with open(f’{tmp}_data.json’, ‘r’, encoding=’utf-8’) as f:\n",
    "with open('data.json', 'r') as f:\n",
    "    objects = ijson.items(f, 'results.item')\n",
    "    for row in objects:\n",
    "        if row['text'].startswith(\"RT\") == False:\n",
    "            city.append(row['place']['name'])\n",
    "            location.append(row['coordinates'])\n",
    "            time.append(row['created_at'])\n",
    "            text.append(row['text'])\n",
    "\n",
    "data = pd.DataFrame({\"text\":text,\"time\":time,\"city\":city,\"location\":location},columns=[\"text\",\"time\",\"city\",\"location\"])\n",
    "data['time'] = pd.to_datetime(data['time']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "# from textblob import TextBlob\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "import string\n",
    "import re\n",
    "\n",
    "# remove non ASCII characters\n",
    "def strip_non_ascii(data_str):\n",
    "    ''' Returns the string without non ASCII characters'''\n",
    "    stripped = (c for c in data_str if 0 < ord(c) < 127)\n",
    "    return ''.join(stripped)\n",
    "# setup pyspark udf function\n",
    "strip_non_ascii_udf = udf(strip_non_ascii, StringType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import findspark\n",
    "# findspark.init()\n",
    "spark = SparkSession.builder.appName('NLP').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------+--------+--------------------+\n",
      "|                text|      time|     city|location|       text_non_asci|\n",
      "+--------------------+----------+---------+--------+--------------------+\n",
      "|Brilliant thread....|2020-08-31|Melbourne|    null|Brilliant thread....|\n",
      "|@TimWilsonMP Have...|2020-08-31|Melbourne|    null|@TimWilsonMP Have...|\n",
      "|@Rdene915 @Christ...|2020-08-31|Melbourne|    null|@Rdene915 @Christ...|\n",
      "|A photo of you in...|2020-08-31|Melbourne|    null|A photo of you in...|\n",
      "|@IndyCat14 @JoyOf...|2020-08-31|Melbourne|    null|@IndyCat14 @JoyOf...|\n",
      "|@BuckleyIOP It re...|2020-08-31|Melbourne|    null|@BuckleyIOP It re...|\n",
      "|@kruevans But you...|2020-08-31|Melbourne|    null|@kruevans But you...|\n",
      "|@johniadarola I d...|2020-08-31|Melbourne|    null|@johniadarola I d...|\n",
      "|My sister turns 7...|2020-08-31|Melbourne|    null|My sister turns 7...|\n",
      "|@kruevans It’s sh...|2020-08-31|Melbourne|    null|@kruevans Its shi...|\n",
      "|@runwader Cannot ...|2020-08-31|Melbourne|    null|@runwader Cannot ...|\n",
      "|@abcmelbourne mor...|2020-08-31|Melbourne|    null|@abcmelbourne mor...|\n",
      "|#VICTORIA #Parlia...|2020-08-31|Melbourne|    null|#VICTORIA #Parlia...|\n",
      "|@profsarahj Sadly...|2020-08-31|Melbourne|    null|@profsarahj Sadly...|\n",
      "|@ChristineBemis2 ...|2020-08-31|Melbourne|    null|@ChristineBemis2 ...|\n",
      "|@MonmouthTrack Ag...|2020-08-31|Melbourne|    null|@MonmouthTrack Ag...|\n",
      "|@CardsSIUCIllini ...|2020-08-31|Melbourne|    null|@CardsSIUCIllini ...|\n",
      "|Beautiful Scotlan...|2020-08-31|Melbourne|    null|Beautiful Scotlan...|\n",
      "|@johnweber94 @sha...|2020-08-31|Melbourne|    null|@johnweber94 @sha...|\n",
      "|That's what... Ma...|2020-08-31|  Geelong|    null|That's what... Ma...|\n",
      "+--------------------+----------+---------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data)\n",
    "df = df.withColumn('text_non_asci',strip_non_ascii_udf(df['text']))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed abbreviation\n",
    "def fix_abbreviation(data_str):\n",
    "    data_str = data_str.lower()\n",
    "    data_str = re.sub(r'\\bthats\\b', 'that is', data_str)\n",
    "    data_str = re.sub(r'\\bive\\b', 'i have', data_str)\n",
    "    data_str = re.sub(r'\\bim\\b', 'i am', data_str)\n",
    "    data_str = re.sub(r'\\bya\\b', 'yeah', data_str)\n",
    "    data_str = re.sub(r'\\bcant\\b', 'can not', data_str)\n",
    "    data_str = re.sub(r'\\bdont\\b', 'do not', data_str)\n",
    "    data_str = re.sub(r'\\bwont\\b', 'will not', data_str)\n",
    "    data_str = re.sub(r'\\bid\\b', 'i would', data_str)\n",
    "    data_str = re.sub(r'wtf', 'what the fuck', data_str)\n",
    "    data_str = re.sub(r'\\bwth\\b', 'what the hell', data_str)\n",
    "    data_str = re.sub(r'\\br\\b', 'are', data_str)\n",
    "    data_str = re.sub(r'\\bu\\b', 'you', data_str)\n",
    "    data_str = re.sub(r'\\bk\\b', 'OK', data_str)\n",
    "    data_str = re.sub(r'\\bsux\\b', 'sucks', data_str)\n",
    "    data_str = re.sub(r'\\bno+\\b', 'no', data_str)\n",
    "    data_str = re.sub(r'\\bcoo+\\b', 'cool', data_str)\n",
    "    data_str = re.sub(r'rt\\b', '', data_str)\n",
    "    data_str = data_str.strip()\n",
    "    return data_str\n",
    "\n",
    "fix_abbreviation_udf = udf(fix_abbreviation, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------+--------+--------------------+--------------------+\n",
      "|                text|      time|     city|location|       text_non_asci|        fixed_abbrev|\n",
      "+--------------------+----------+---------+--------+--------------------+--------------------+\n",
      "|Brilliant thread....|2020-08-31|Melbourne|    null|Brilliant thread....|brilliant thread....|\n",
      "|@TimWilsonMP Have...|2020-08-31|Melbourne|    null|@TimWilsonMP Have...|@timwilsonmp have...|\n",
      "|@Rdene915 @Christ...|2020-08-31|Melbourne|    null|@Rdene915 @Christ...|@rdene915 @christ...|\n",
      "|A photo of you in...|2020-08-31|Melbourne|    null|A photo of you in...|a photo of you in...|\n",
      "|@IndyCat14 @JoyOf...|2020-08-31|Melbourne|    null|@IndyCat14 @JoyOf...|@indycat14 @joyof...|\n",
      "+--------------------+----------+---------+--------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('fixed_abbrev',fix_abbreviation_udf(df['text_non_asci']))\n",
    "df.show(5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_features(data_str):\n",
    "    # compile regex\n",
    "    url_re = re.compile('https?://(www.)?\\w+\\.\\w+(/\\w+)*/?')\n",
    "    punc_re = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    num_re = re.compile('(\\\\d+)')\n",
    "    mention_re = re.compile('@(\\w+)')\n",
    "    alpha_num_re = re.compile(\"^[a-z0-9_.]+$\")\n",
    "    # convert to lowercase\n",
    "    data_str = data_str.lower()\n",
    "    # remove hyperlinks\n",
    "    data_str = url_re.sub(' ', data_str)\n",
    "    # remove @mentions\n",
    "    data_str = mention_re.sub(' ', data_str)\n",
    "    # remove puncuation\n",
    "    data_str = punc_re.sub(' ', data_str)\n",
    "    # remove numeric 'words'\n",
    "    data_str = num_re.sub(' ', data_str)\n",
    "    # remove non a-z 0-9 characters and words shorter than 1 characters\n",
    "    list_pos = 0\n",
    "    cleaned_str = ''\n",
    "    for word in data_str.split():\n",
    "        if list_pos == 0:\n",
    "            if alpha_num_re.match(word) and len(word) > 1:\n",
    "                cleaned_str = word\n",
    "            else:\n",
    "                cleaned_str = ' '\n",
    "        else:\n",
    "            if alpha_num_re.match(word) and len(word) > 1:\n",
    "                cleaned_str = cleaned_str + ' ' + word\n",
    "            else:\n",
    "                cleaned_str += ' '\n",
    "        list_pos += 1\n",
    "    # remove unwanted space, *.split() will automatically split on\n",
    "    # whitespace and discard duplicates, the \" \".join() joins the\n",
    "    # resulting list into one string.\n",
    "    return \" \".join(cleaned_str.split())\n",
    "# setup pyspark udf function\n",
    "remove_features_udf = udf(remove_features, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------+--------+--------------------+--------------------+--------------------+\n",
      "|                text|      time|     city|location|       text_non_asci|        fixed_abbrev|             removed|\n",
      "+--------------------+----------+---------+--------+--------------------+--------------------+--------------------+\n",
      "|Brilliant thread....|2020-08-31|Melbourne|    null|Brilliant thread....|brilliant thread....|brilliant thread ...|\n",
      "|@TimWilsonMP Have...|2020-08-31|Melbourne|    null|@TimWilsonMP Have...|@timwilsonmp have...|have the courage ...|\n",
      "|@Rdene915 @Christ...|2020-08-31|Melbourne|    null|@Rdene915 @Christ...|@rdene915 @christ...|build it and they...|\n",
      "|A photo of you in...|2020-08-31|Melbourne|    null|A photo of you in...|a photo of you in...|photo of you in j...|\n",
      "|@IndyCat14 @JoyOf...|2020-08-31|Melbourne|    null|@IndyCat14 @JoyOf...|@indycat14 @joyof...|                    |\n",
      "+--------------------+----------+---------+--------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('removed',remove_features_udf(df['fixed_abbrev']))\n",
    "df.show(5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "def sentiment_analysis(text):\n",
    "\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "sentiment_analysis_udf = udf(sentiment_analysis , FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------+--------+--------------------+--------------------+--------------------+---------------+\n",
      "|                text|      time|     city|location|       text_non_asci|        fixed_abbrev|             removed|sentiment_score|\n",
      "+--------------------+----------+---------+--------+--------------------+--------------------+--------------------+---------------+\n",
      "|Brilliant thread....|2020-08-31|Melbourne|    null|Brilliant thread....|brilliant thread....|brilliant thread ...|     0.53333336|\n",
      "|@TimWilsonMP Have...|2020-08-31|Melbourne|    null|@TimWilsonMP Have...|@timwilsonmp have...|have the courage ...|            0.0|\n",
      "|@Rdene915 @Christ...|2020-08-31|Melbourne|    null|@Rdene915 @Christ...|@rdene915 @christ...|build it and they...|            0.0|\n",
      "|A photo of you in...|2020-08-31|Melbourne|    null|A photo of you in...|a photo of you in...|photo of you in j...|            0.0|\n",
      "|@IndyCat14 @JoyOf...|2020-08-31|Melbourne|    null|@IndyCat14 @JoyOf...|@indycat14 @joyof...|                    |            0.0|\n",
      "+--------------------+----------+---------+--------+--------------------+--------------------+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df  = df.withColumn(\"sentiment_score\", sentiment_analysis_udf( df['removed'] ))\n",
    "df.show(5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition(r):\n",
    "    if (r >=0.1):\n",
    "        label = \"positive\"\n",
    "    elif(r <= -0.1):\n",
    "        label = \"negative\"\n",
    "    else:\n",
    "        label = \"neutral\"\n",
    "    return label\n",
    "\n",
    "sentiment_udf = udf(lambda x: condition(x), StringType())\n",
    "df  = df.withColumn(\"sentiment\", sentiment_udf( df['sentiment_score'] ))\n",
    "SA_results = df.select('text','time','sentiment_score','sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_results.show(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SA_results.groupBy(['time','sentiment'])\\\n",
    "            .count()\\\n",
    "            .orderBy(\"time\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
